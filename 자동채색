{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmggboss78/handson-ml/blob/master/%EC%9E%90%EB%8F%99%EC%B1%84%EC%83%89\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IFnjZIYNFODN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Input, MaxPooling2D, UpSampling2D, Lambda\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuceCzh0FW1r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnVsLAi6FgsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = '/gdrive/My drive/img/colorize'\n",
        "data_lists = glob.glob(os.path.join(data_path, '*.jpg'))\n",
        "\n",
        "val_n_sample = math.floor(len(data_lists)*0.1)\n",
        "test_n_sample = math.floor(len(data_lists)*0.1)\n",
        "train_n_sample = len(data_lists) - val_n_sample - test_n_sample\n",
        "\n",
        "val_lists = data_lists[:val_n_sample]\n",
        "test_lists = data_lists[val_n_sample:val_n_sample + test_n_sample]\n",
        "train_lists = data_lists[val_n_sample + test_n_sample:train_n_sample + val_n_sample + test_n_sample]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vL6Or9RxFr7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "img_size = 224\n",
        "def rgb2lab(rgb):\n",
        "    assert rgb.dtype == 'uint8'\n",
        "    return cv2.cvtColor(rgb, cv2.COLOR_RGB2Lab)\n",
        "\n",
        "def lab2rgb(lab):\n",
        "    assert lab.dtype == 'uint8'\n",
        "    return cv2.cvtColor(lab, cv2.COLOR_Lab2RGB)\n",
        "\n",
        "def get_lab_from_data_list(data_list):\n",
        "    x_lab = []\n",
        "    for f in data_list:\n",
        "        rgb = img_to_array(\n",
        "            load_img(\n",
        "                f, \n",
        "                target_size=(img_size, img_size)\n",
        "            )\n",
        "        ).astype(np.uint8)\n",
        "        lab = rgb2lab(rgb)\n",
        "        x_lab.append(lab)\n",
        "    return np.stack(x_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quJEiUkSFtFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers import Conv2DTranspose\n",
        "\n",
        "\n",
        "autoencoder = Sequential()\n",
        "# Encoder\n",
        "autoencoder.add(\n",
        "    Conv2D(\n",
        "        32, \n",
        "        (3, 3), \n",
        "        (1, 1), \n",
        "        activation='relu', \n",
        "        padding='same', \n",
        "        input_shape=(224, 224, 1)\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        (2, 2),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2D(\n",
        "        128,\n",
        "        (3, 3), \n",
        "        (2, 2), \n",
        "        activation='relu', \n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2D(\n",
        "        256, \n",
        "        (3, 3), \n",
        "        (2, 2), \n",
        "        activation='relu', \n",
        "        padding='same')\n",
        ")\n",
        "# Decoder\n",
        "autoencoder.add(\n",
        "    Conv2DTranspose(\n",
        "        128, \n",
        "        (3, 3), \n",
        "        (2, 2), \n",
        "        activation='relu', \n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2DTranspose(\n",
        "        64,\n",
        "        (3, 3), \n",
        "        (2, 2), \n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2DTranspose(\n",
        "        32,\n",
        "        (3, 3), \n",
        "        (2, 2), \n",
        "        activation='relu', \n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.add(\n",
        "    Conv2D(\n",
        "        2, \n",
        "        (1, 1), \n",
        "        (1, 1), \n",
        "        activation='relu', \n",
        "        padding='same'\n",
        "    )\n",
        ")\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNpJ2uqeFwqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_with_preprocessing(data_list, batch_size, shuffle=False):\n",
        "    while True:\n",
        "        if shuffle:\n",
        "            np.random.shuffle(data_list)\n",
        "        for i in range(0, len(data_list), batch_size):\n",
        "            batch_list = data_list[i:i + batch_size]\n",
        "            batch_lab = get_lab_from_data_list(batch_list)\n",
        "            batch_l = batch_lab[:, :, :, 0:1]\n",
        "            batch_ab = batch_lab[:, :, :, 1:]\n",
        "            yield (batch_l, batch_ab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6H8CT0WF1Sa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "\n",
        "train_gen = generator_with_preprocessing(train_lists, batch_size, shuffle=True)\n",
        "val_gen = generator_with_preprocessing(val_lists, batch_size)\n",
        "test_gen = generator_with_preprocessing(test_lists, batch_size)\n",
        "\n",
        "train_steps = math.ceil(len(train_lists)/batch_size)\n",
        "val_steps = math.ceil(len(val_lists)/batch_size)\n",
        "test_steps = math.ceil(len(test_lists)/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VwSml-DIyZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs= 150\n",
        "    \n",
        "autoencoder.fit_generator(\n",
        "    generator=train_gen,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=val_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}